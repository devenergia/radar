# RAD-210: Scheduler Celery (30 min)

**Fase:** 3 - Infrastructure Layer
**Tipo:** Background Jobs
**Prioridade:** Alta
**Status:** PENDENTE
**Dependencias:** RAD-206, RAD-209
**Base Legal:** REN 1.137/2025 - Art. 106

## Objetivo

Configurar Celery Beat para atualizar dados do mapa a cada 30 minutos.

## Localizacao

```
backend/
├── celery_app.py
├── tasks/
│   └── mapa_tasks.py
└── celery_config.py
```

## Especificacao

### Requisito Legal (REN 1.137 Art. 106)

> "As informacoes divulgadas devem ser atualizadas, no minimo, a cada 30 minutos"

### Tasks Celery

| Task | Frequencia | Descricao |
|------|------------|-----------|
| `refresh_mapa_cache` | 30 min | Atualiza cache do mapa |
| `refresh_mv_portal` | 30 min | Refresh da Materialized View |
| `calcular_estatisticas` | 30 min | Recalcula metricas agregadas |

## Implementacao

### Configuracao Celery

```python
# backend/celery_config.py
"""Configuracao do Celery para tarefas agendadas."""
from celery.schedules import crontab


# Configuracao do Broker (Redis)
broker_url = "redis://localhost:6379/0"
result_backend = "redis://localhost:6379/0"

# Configuracao de timezone
timezone = "America/Boa_Vista"
enable_utc = True

# Configuracao de tarefas
task_serializer = "json"
result_serializer = "json"
accept_content = ["json"]

# Configuracao de retry
task_acks_late = True
task_reject_on_worker_lost = True

# Beat Schedule - REN 1.137 exige 30 minutos
beat_schedule = {
    "refresh-mapa-cache-every-30-min": {
        "task": "tasks.mapa_tasks.refresh_mapa_cache",
        "schedule": crontab(minute="*/30"),
        "options": {"queue": "mapa"},
    },
    "refresh-mv-portal-every-30-min": {
        "task": "tasks.mapa_tasks.refresh_mv_portal",
        "schedule": crontab(minute="*/30"),
        "options": {"queue": "database"},
    },
    "calcular-estatisticas-every-30-min": {
        "task": "tasks.mapa_tasks.calcular_estatisticas",
        "schedule": crontab(minute="*/30"),
        "options": {"queue": "mapa"},
    },
}
```

### Celery App

```python
# backend/celery_app.py
"""Aplicacao Celery para background jobs."""
from celery import Celery

app = Celery("radar")
app.config_from_object("celery_config")

# Auto-discover tasks
app.autodiscover_tasks(["tasks"])


@app.on_after_configure.connect
def setup_periodic_tasks(sender, **kwargs):
    """Configura tasks periodicas."""
    # As tasks sao configuradas via beat_schedule no config
    pass
```

### Tasks do Mapa

```python
# backend/tasks/mapa_tasks.py
"""Tasks Celery para atualizacao do mapa."""
import logging
from celery import shared_task
from datetime import datetime

from shared.infrastructure.database.oracle_connection import get_session
from shared.infrastructure.cache.memory_cache import MemoryCacheService
from apps.mapa_interrupcoes.repositories.oracle_mapa_repository import (
    OracleMapaRepository,
)
from apps.mapa_interrupcoes.use_cases.get_interrupcoes_mapa import (
    GetInterrupcoesMapaUseCase,
)

logger = logging.getLogger(__name__)


@shared_task(
    bind=True,
    name="tasks.mapa_tasks.refresh_mapa_cache",
    max_retries=3,
    default_retry_delay=60,
)
def refresh_mapa_cache(self) -> dict:
    """
    Atualiza cache do mapa de interrupcoes.

    Conforme REN 1.137/2025 Art. 106:
    - Atualizacao minima a cada 30 minutos

    Returns:
        Dict com resultado da operacao
    """
    try:
        logger.info("Iniciando refresh do cache do mapa")

        # Obter dependencias
        async def _execute():
            async with get_session() as session:
                repository = OracleMapaRepository(session)
                cache = MemoryCacheService()

                use_case = GetInterrupcoesMapaUseCase(
                    repository=repository,
                    cache=cache,
                )

                # Forcar refresh invalidando cache
                await cache.invalidate("mapa:interrupcoes")

                # Executar busca (vai popular o cache)
                result = await use_case.execute()

                if result.is_success:
                    return {
                        "status": "success",
                        "interrupcoes": len(result.value.interrupcoes),
                        "timestamp": datetime.now().isoformat(),
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.error,
                        "timestamp": datetime.now().isoformat(),
                    }

        import asyncio
        return asyncio.run(_execute())

    except Exception as exc:
        logger.error(f"Erro no refresh do cache: {exc}")
        raise self.retry(exc=exc)


@shared_task(
    bind=True,
    name="tasks.mapa_tasks.refresh_mv_portal",
    max_retries=3,
    default_retry_delay=120,
)
def refresh_mv_portal(self) -> dict:
    """
    Executa refresh da Materialized View do portal.

    Returns:
        Dict com resultado da operacao
    """
    try:
        logger.info("Iniciando refresh da MV_PORTAL_PUBLICO")

        async def _execute():
            async with get_session() as session:
                # Executar refresh via DBMS_MVIEW
                await session.execute("""
                    BEGIN
                        DBMS_MVIEW.REFRESH('RADAR.MV_PORTAL_PUBLICO', 'C');
                    END;
                """)
                await session.commit()

                return {
                    "status": "success",
                    "timestamp": datetime.now().isoformat(),
                }

        import asyncio
        return asyncio.run(_execute())

    except Exception as exc:
        logger.error(f"Erro no refresh da MV: {exc}")
        raise self.retry(exc=exc)


@shared_task(
    bind=True,
    name="tasks.mapa_tasks.calcular_estatisticas",
    max_retries=3,
    default_retry_delay=60,
)
def calcular_estatisticas(self) -> dict:
    """
    Calcula e cacheia estatisticas agregadas.

    Returns:
        Dict com estatisticas calculadas
    """
    try:
        logger.info("Calculando estatisticas do mapa")

        async def _execute():
            async with get_session() as session:
                repository = OracleMapaRepository(session)
                cache = MemoryCacheService()

                # Buscar estatisticas
                stats = await repository.buscar_estatisticas()

                # Cachear por 30 minutos
                await cache.set(
                    "mapa:estatisticas",
                    {
                        "total_interrupcoes": stats.total_interrupcoes,
                        "total_ucs_afetadas": stats.total_ucs_afetadas,
                        "chi_total": stats.chi_total,
                        "equipes_em_campo": stats.equipes_em_campo,
                        "por_faixa": {
                            k.value: v for k, v in stats.por_faixa.items()
                        },
                        "por_municipio": stats.por_municipio,
                    },
                    1800,  # 30 minutos
                )

                return {
                    "status": "success",
                    "total_interrupcoes": stats.total_interrupcoes,
                    "timestamp": datetime.now().isoformat(),
                }

        import asyncio
        return asyncio.run(_execute())

    except Exception as exc:
        logger.error(f"Erro ao calcular estatisticas: {exc}")
        raise self.retry(exc=exc)


@shared_task(name="tasks.mapa_tasks.health_check")
def health_check() -> dict:
    """Health check das tasks."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
    }
```

### Docker Compose para Celery

```yaml
# docker-compose.celery.yml
version: "3.8"

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  celery-worker:
    build: .
    command: celery -A celery_app worker -l info -Q mapa,database
    environment:
      - REDIS_URL=redis://redis:6379/0
      - ORACLE_DSN=${ORACLE_DSN}
    depends_on:
      - redis
    volumes:
      - ./backend:/app

  celery-beat:
    build: .
    command: celery -A celery_app beat -l info
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
      - celery-worker
    volumes:
      - ./backend:/app

volumes:
  redis_data:
```

## Testes TDD (Escrever PRIMEIRO)

```python
# tests/unit/tasks/test_mapa_tasks.py
import pytest
from unittest.mock import patch, AsyncMock, MagicMock
from datetime import datetime

from tasks.mapa_tasks import (
    refresh_mapa_cache,
    refresh_mv_portal,
    calcular_estatisticas,
    health_check,
)


class TestRefreshMapaCache:
    """Testes para task refresh_mapa_cache."""

    @patch("tasks.mapa_tasks.get_session")
    @patch("tasks.mapa_tasks.MemoryCacheService")
    @patch("tasks.mapa_tasks.OracleMapaRepository")
    @patch("tasks.mapa_tasks.GetInterrupcoesMapaUseCase")
    def test_deve_retornar_sucesso(
        self,
        mock_use_case_class,
        mock_repo_class,
        mock_cache_class,
        mock_session,
    ):
        """Task deve retornar status success."""
        # Setup mocks
        mock_result = MagicMock()
        mock_result.is_success = True
        mock_result.value.interrupcoes = []

        mock_use_case = AsyncMock()
        mock_use_case.execute.return_value = mock_result
        mock_use_case_class.return_value = mock_use_case

        result = refresh_mapa_cache()

        assert result["status"] == "success"
        assert "timestamp" in result

    @patch("tasks.mapa_tasks.get_session")
    def test_deve_fazer_retry_em_erro(self, mock_session):
        """Task deve fazer retry em caso de erro."""
        mock_session.side_effect = Exception("Connection error")

        with pytest.raises(Exception):
            refresh_mapa_cache()


class TestRefreshMvPortal:
    """Testes para task refresh_mv_portal."""

    @patch("tasks.mapa_tasks.get_session")
    def test_deve_executar_refresh_dbms_mview(self, mock_session):
        """Task deve chamar DBMS_MVIEW.REFRESH."""
        mock_session_instance = AsyncMock()
        mock_session.return_value.__aenter__.return_value = (
            mock_session_instance
        )

        result = refresh_mv_portal()

        mock_session_instance.execute.assert_called()
        assert result["status"] == "success"


class TestCalcularEstatisticas:
    """Testes para task calcular_estatisticas."""

    @patch("tasks.mapa_tasks.get_session")
    @patch("tasks.mapa_tasks.MemoryCacheService")
    @patch("tasks.mapa_tasks.OracleMapaRepository")
    def test_deve_cachear_estatisticas(
        self, mock_repo_class, mock_cache_class, mock_session
    ):
        """Task deve salvar estatisticas no cache."""
        mock_stats = MagicMock()
        mock_stats.total_interrupcoes = 10
        mock_stats.total_ucs_afetadas = 1000
        mock_stats.chi_total = 5000.0
        mock_stats.equipes_em_campo = 5
        mock_stats.por_faixa = {}
        mock_stats.por_municipio = {}

        mock_repo = AsyncMock()
        mock_repo.buscar_estatisticas.return_value = mock_stats
        mock_repo_class.return_value = mock_repo

        mock_cache = AsyncMock()
        mock_cache_class.return_value = mock_cache

        result = calcular_estatisticas()

        mock_cache.set.assert_called()
        assert result["status"] == "success"
        assert result["total_interrupcoes"] == 10


class TestHealthCheck:
    """Testes para task health_check."""

    def test_deve_retornar_healthy(self):
        """Task deve retornar status healthy."""
        result = health_check()

        assert result["status"] == "healthy"
        assert "timestamp" in result
```

## Criterios de Aceite

- [ ] Celery configurado com Redis
- [ ] Beat schedule a cada 30 minutos
- [ ] Task refresh_mapa_cache funcional
- [ ] Task refresh_mv_portal funcional
- [ ] Task calcular_estatisticas funcional
- [ ] Retry em caso de falha
- [ ] Docker Compose para desenvolvimento
- [ ] Testes passando

## Comando de Execucao

```bash
# Iniciar Redis
docker-compose -f docker-compose.celery.yml up redis -d

# Iniciar Worker
celery -A celery_app worker -l info -Q mapa,database

# Iniciar Beat
celery -A celery_app beat -l info

# Executar task manualmente
celery -A celery_app call tasks.mapa_tasks.refresh_mapa_cache

# Monitorar
celery -A celery_app flower

# Testes
pytest tests/unit/tasks/test_mapa_tasks.py -v
```
