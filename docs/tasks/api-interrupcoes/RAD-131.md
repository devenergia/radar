# RAD-131: Jobs Agendados com APScheduler

| Campo | Valor |
|-------|-------|
| **ID** | RAD-131 |
| **Fase** | 8 - Otimizações AME |
| **Tipo** | Feature |
| **Prioridade** | ALTA |
| **Status** | Pendente |
| **Dependências** | RAD-109 (OracleInterrupcaoRepository) |

## Objetivo

Implementar sistema de jobs agendados usando APScheduler para pré-aquecimento de cache a cada 30 minutos, similar ao BullMQ do AME mas mantendo a stack Python e Clean Architecture do RADAR.

## Localização

```
backend/
├── shared/
│   └── infrastructure/
│       └── scheduler/
│           ├── __init__.py
│           ├── scheduler_service.py      # APScheduler wrapper
│           └── jobs/
│               ├── __init__.py
│               └── cache_warmup_job.py   # Job de pré-aquecimento
└── apps/
    └── api_interrupcoes/
        └── jobs/
            └── interrupcao_cache_warmup.py  # Job específico da API
```

## Especificação

### Contexto

O AME utiliza BullMQ + Redis para executar jobs a cada 30 minutos que pré-aquecem o cache com dados de interrupções. Isso garante que as consultas da ANEEL sempre encontrem dados em cache, reduzindo latência e carga no Oracle.

### Regras de Negócio

1. **Intervalo de Execução**: Job deve executar a cada 30 minutos (padrão cron: `*/30 * * * *`)
2. **Pré-Aquecimento**: Buscar dados do Oracle e popular cache ANTES de expirar
3. **Tolerância a Falhas**: Se job falhar, cache stale continua disponível
4. **Logging**: Registrar execuções, duração e erros
5. **Health Check**: Expor status do scheduler via endpoint `/health`

### Referência AME (TypeScript)

```typescript
// AME: src/work/InterrupcaoAtivaWork.ts
const pattern = '*/30 * * * *'
const queue = new Queue(queueName, { connection: redisConnection })
await queue.add(jobName, {...}, { repeat: { pattern } })

new Worker(queueName, async () => {
    await InterrupcaoEnergiaController.iniciar()
}, { connection: redisConnection })
```

## Implementação

### 1. Dependência APScheduler

```toml
# pyproject.toml
[project]
dependencies = [
    # ... existentes
    "apscheduler>=3.10.4",
]
```

### 2. Scheduler Service (Infrastructure)

```python
# backend/shared/infrastructure/scheduler/scheduler_service.py
"""Serviço de agendamento de jobs usando APScheduler."""

from __future__ import annotations

import logging
from typing import Callable, Protocol

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

logger = logging.getLogger(__name__)


class Job(Protocol):
    """Protocol para jobs agendados."""

    async def execute(self) -> None:
        """Executa o job."""
        ...

    @property
    def name(self) -> str:
        """Nome do job para logging."""
        ...


class SchedulerService:
    """Wrapper para APScheduler com interface limpa."""

    def __init__(self) -> None:
        self._scheduler = AsyncIOScheduler()
        self._jobs: dict[str, Job] = {}

    def add_cron_job(
        self,
        job: Job,
        cron_expression: str,
    ) -> None:
        """
        Adiciona job com expressão cron.

        Args:
            job: Instância do job a executar
            cron_expression: Expressão cron (ex: "*/30 * * * *")
        """
        minute, hour, day, month, day_of_week = cron_expression.split()

        trigger = CronTrigger(
            minute=minute,
            hour=hour,
            day=day,
            month=month,
            day_of_week=day_of_week,
        )

        self._scheduler.add_job(
            self._wrap_job(job),
            trigger=trigger,
            id=job.name,
            name=job.name,
            replace_existing=True,
        )
        self._jobs[job.name] = job
        logger.info(f"Job registrado: {job.name} com cron '{cron_expression}'")

    async def _wrap_job(self, job: Job) -> Callable:
        """Wrapper para adicionar logging e tratamento de erros."""
        async def wrapped() -> None:
            logger.info(f"Iniciando job: {job.name}")
            try:
                await job.execute()
                logger.info(f"Job finalizado com sucesso: {job.name}")
            except Exception as e:
                logger.error(f"Erro no job {job.name}: {e}", exc_info=True)

        return wrapped

    def start(self) -> None:
        """Inicia o scheduler."""
        if not self._scheduler.running:
            self._scheduler.start()
            logger.info("Scheduler iniciado")

    def stop(self) -> None:
        """Para o scheduler."""
        if self._scheduler.running:
            self._scheduler.shutdown(wait=False)
            logger.info("Scheduler parado")

    def is_running(self) -> bool:
        """Verifica se scheduler está rodando."""
        return self._scheduler.running

    def get_jobs_status(self) -> dict:
        """Retorna status de todos os jobs."""
        return {
            "running": self.is_running(),
            "jobs": [
                {
                    "name": job.id,
                    "next_run": str(job.next_run_time),
                }
                for job in self._scheduler.get_jobs()
            ],
        }


# Singleton
scheduler_service = SchedulerService()
```

### 3. Job de Pré-Aquecimento de Cache

```python
# backend/apps/api_interrupcoes/jobs/interrupcao_cache_warmup.py
"""Job para pré-aquecimento de cache de interrupções."""

from __future__ import annotations

import logging
from datetime import datetime

from backend.shared.infrastructure.cache.memory_cache import memory_cache
from backend.apps.api_interrupcoes.use_cases.get_interrupcoes_ativas import (
    GetInterrupcoesAtivasUseCase,
)

logger = logging.getLogger(__name__)


class InterrupcaoCacheWarmupJob:
    """
    Job que pré-aquece o cache de interrupções ativas.

    Executa a cada 30 minutos para garantir que dados
    estejam sempre disponíveis em cache para consultas ANEEL.
    """

    CACHE_KEY = "interrupcoes:ativas:v1"
    CRON_EXPRESSION = "*/30 * * * *"

    def __init__(
        self,
        use_case: GetInterrupcoesAtivasUseCase,
    ) -> None:
        self._use_case = use_case

    @property
    def name(self) -> str:
        return "interrupcao_cache_warmup"

    async def execute(self) -> None:
        """
        Executa pré-aquecimento do cache.

        1. Busca dados frescos do Oracle
        2. Atualiza cache com TTL renovado
        3. Registra métricas de execução
        """
        start_time = datetime.now()

        # Força busca do Oracle (ignora cache)
        result = await self._use_case.execute(force_refresh=True)

        if result.is_failure:
            logger.error(f"Falha no warmup: {result.error}")
            raise RuntimeError(f"Cache warmup failed: {result.error}")

        duration_ms = (datetime.now() - start_time).total_seconds() * 1000

        logger.info(
            "Cache warmup concluído",
            extra={
                "duration_ms": duration_ms,
                "items_cached": len(result.value) if result.value else 0,
                "cache_key": self.CACHE_KEY,
            },
        )
```

### 4. Integração com Lifecycle da App

```python
# backend/apps/api_interrupcoes/main.py
from contextlib import asynccontextmanager
from fastapi import FastAPI

from backend.shared.infrastructure.scheduler.scheduler_service import scheduler_service
from backend.apps.api_interrupcoes.jobs.interrupcao_cache_warmup import (
    InterrupcaoCacheWarmupJob,
)
from backend.apps.api_interrupcoes.dependencies import get_interrupcoes_use_case


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifecycle da aplicação."""
    # Startup
    await oracle_pool.initialize()
    await memory_cache.start()

    # Registrar jobs
    warmup_job = InterrupcaoCacheWarmupJob(
        use_case=await get_interrupcoes_use_case(),
    )
    scheduler_service.add_cron_job(
        job=warmup_job,
        cron_expression=warmup_job.CRON_EXPRESSION,
    )
    scheduler_service.start()

    # Executar warmup inicial
    await warmup_job.execute()

    yield

    # Shutdown
    scheduler_service.stop()
    await memory_cache.stop()
    await oracle_pool.close()
```

### 5. Endpoint de Health com Status do Scheduler

```python
# backend/apps/api_interrupcoes/routes/health.py
from fastapi import APIRouter
from backend.shared.infrastructure.scheduler.scheduler_service import scheduler_service

router = APIRouter(tags=["Health"])


@router.get("/health")
async def health_check() -> dict:
    """Health check com status do scheduler."""
    return {
        "status": "healthy",
        "scheduler": scheduler_service.get_jobs_status(),
        "cache": memory_cache.get_stats(),
        "database": await oracle_pool.health_check(),
    }
```

## Testes TDD

### Teste Unitário - SchedulerService

```python
# backend/tests/unit/infrastructure/scheduler/test_scheduler_service.py
import pytest
from unittest.mock import AsyncMock, MagicMock

from backend.shared.infrastructure.scheduler.scheduler_service import SchedulerService


class TestSchedulerService:
    @pytest.fixture
    def scheduler(self):
        return SchedulerService()

    @pytest.fixture
    def mock_job(self):
        job = MagicMock()
        job.name = "test_job"
        job.execute = AsyncMock()
        return job

    def test_deve_adicionar_job_com_cron_expression(
        self, scheduler: SchedulerService, mock_job
    ):
        # Act
        scheduler.add_cron_job(mock_job, "*/30 * * * *")

        # Assert
        jobs = scheduler.get_jobs_status()
        assert len(jobs["jobs"]) == 1
        assert jobs["jobs"][0]["name"] == "test_job"

    def test_deve_iniciar_e_parar_scheduler(self, scheduler: SchedulerService):
        # Act & Assert
        assert scheduler.is_running() is False

        scheduler.start()
        assert scheduler.is_running() is True

        scheduler.stop()
        assert scheduler.is_running() is False

    def test_deve_retornar_status_dos_jobs(
        self, scheduler: SchedulerService, mock_job
    ):
        scheduler.add_cron_job(mock_job, "*/30 * * * *")
        scheduler.start()

        status = scheduler.get_jobs_status()

        assert status["running"] is True
        assert len(status["jobs"]) == 1

        scheduler.stop()
```

### Teste Unitário - CacheWarmupJob

```python
# backend/tests/unit/jobs/test_interrupcao_cache_warmup.py
import pytest
from unittest.mock import AsyncMock, MagicMock
from datetime import datetime

from backend.apps.api_interrupcoes.jobs.interrupcao_cache_warmup import (
    InterrupcaoCacheWarmupJob,
)
from backend.shared.domain.result import Result


class TestInterrupcaoCacheWarmupJob:
    @pytest.fixture
    def mock_use_case(self):
        use_case = MagicMock()
        use_case.execute = AsyncMock()
        return use_case

    @pytest.fixture
    def job(self, mock_use_case):
        return InterrupcaoCacheWarmupJob(use_case=mock_use_case)

    def test_deve_ter_nome_correto(self, job):
        assert job.name == "interrupcao_cache_warmup"

    def test_deve_ter_cron_expression_30_minutos(self, job):
        assert job.CRON_EXPRESSION == "*/30 * * * *"

    @pytest.mark.asyncio
    async def test_deve_executar_use_case_com_force_refresh(
        self, job, mock_use_case
    ):
        mock_use_case.execute.return_value = Result.ok([])

        await job.execute()

        mock_use_case.execute.assert_called_once_with(force_refresh=True)

    @pytest.mark.asyncio
    async def test_deve_propagar_erro_quando_use_case_falha(
        self, job, mock_use_case
    ):
        mock_use_case.execute.return_value = Result.fail("Erro de conexão")

        with pytest.raises(RuntimeError, match="Cache warmup failed"):
            await job.execute()
```

### Teste de Integração - Lifecycle

```python
# backend/tests/integration/test_scheduler_lifecycle.py
import pytest
from httpx import AsyncClient

from backend.apps.api_interrupcoes.main import create_app


@pytest.mark.integration
class TestSchedulerLifecycle:
    @pytest.mark.asyncio
    async def test_scheduler_deve_iniciar_com_app(self):
        app = create_app()

        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/health")

        assert response.status_code == 200
        body = response.json()
        assert "scheduler" in body
        assert body["scheduler"]["running"] is True

    @pytest.mark.asyncio
    async def test_health_deve_mostrar_jobs_registrados(self):
        app = create_app()

        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/health")

        body = response.json()
        jobs = body["scheduler"]["jobs"]
        assert any(j["name"] == "interrupcao_cache_warmup" for j in jobs)
```

## Critérios de Aceite

- [ ] APScheduler instalado e configurado
- [ ] SchedulerService implementado com Protocol Job
- [ ] Job de cache warmup executa a cada 30 minutos
- [ ] Warmup inicial executa no startup da app
- [ ] Endpoint /health mostra status do scheduler
- [ ] Logs estruturados para execuções de jobs
- [ ] Testes unitários com cobertura >= 80%
- [ ] Testes de integração para lifecycle
- [ ] Documentação atualizada

## Referências

- [APScheduler Docs](https://apscheduler.readthedocs.io/)
- [AME InterrupcaoAtivaWork.ts](D:\roraima_radar\radar-backend\src\work\InterrupcaoAtivaWork.ts)
- [Ofício Circular 14/2025-SFE/ANEEL](docs/aneel/)
